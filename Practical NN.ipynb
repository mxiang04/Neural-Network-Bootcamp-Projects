{"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom torch.utils.data import Dataset","metadata":{"tags":[],"cell_id":"d0604b30727d47ccb77df39477d8abe6","source_hash":"21e02628","execution_start":1672947282764,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df = pd.read_csv(\"/work/diabetes.csv\")\nX = df.iloc[:, :-1].values\ny = df.iloc[:, -1].values","metadata":{"tags":[],"cell_id":"91d3c15feb784420b551deb232c07bcf","source_hash":"d747dd46","execution_start":1672947106830,"execution_millis":6,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":10},{"cell_type":"code","source":"le = LabelEncoder()\ny = np.array(le.fit_transform(y), dtype=\"float64\")","metadata":{"tags":[],"cell_id":"ada9ca5d9a024c91839f8dfca3a049b4","source_hash":"ae5f5442","execution_start":1672947319320,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":18},{"cell_type":"code","source":"sc = StandardScaler()\nX = torch.tensor(sc.fit_transform(X))\ny = torch.tensor(y)\ny = torch.unsqueeze(y, 1)","metadata":{"tags":[],"cell_id":"25348a8790ba438d82224f3125582a41","source_hash":"dee22385","execution_start":1672947626231,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_77/1798620586.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y = torch.tensor(y)\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"class Dataset(Dataset):\n\n    def __init__(self,x,y):\n        self.x = x\n        self.y = y\n        \n    def __getitem__(self,index):\n        # Get one item from the dataset\n        return self.x[index], self.y[index]\n    \n    def __len__(self):\n        return len(self.x)","metadata":{"tags":[],"cell_id":"f6faf18a15be4de7b765c4b1c01e7b73","source_hash":"557a0a7c","execution_start":1672949495931,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":51},{"cell_type":"code","source":"dataset = Dataset(X, y)","metadata":{"tags":[],"cell_id":"33fab683c3c443e8b8c0c7fe896f50d9","source_hash":"68bf4725","execution_start":1672949500041,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":52},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(dataset = dataset, batch_size = 32, shuffle = True)","metadata":{"tags":[],"cell_id":"419b0ae1401d48d58d96a922de81ec27","source_hash":"26c73ed3","execution_start":1672949502140,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":53},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, input_features):\n        super(Model, self).__init__()\n        self.fc1 = nn.Linear(input_features, 5)\n        self.fc2 = nn.Linear(5, 4)\n        self.fc3 = nn.Linear(4, 3)\n        self.fc4 = nn.Linear(3, 1)\n        self.sigmoid = nn.Sigmoid()\n        self.tanh = nn.Tanh()\n    \n    def forward(self, X):\n        out = self.fc1(X)\n        out = self.tanh(out)\n        out = self.fc2(out)\n        out = self.tanh(out)\n        out = self.fc3(out)\n        out = self.tanh(out)\n        out = self.fc4(out)\n        out = self.sigmoid(out)\n        return out\n","metadata":{"tags":[],"cell_id":"67782b3bada2434f994f84d43e37fa26","source_hash":"e257a7d0","execution_start":1672949569344,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":59},{"cell_type":"code","source":"net = Model(X.shape[1])\ncriterion = torch.nn.BCELoss(size_average = True)\noptimizer = torch.optim.SGD(net.parameters(), lr = 0.1, momentum = 0.9)","metadata":{"tags":[],"cell_id":"2a400e4b002342059ef55764ea58cdab","source_hash":"e6c78507","execution_start":1672949613911,"execution_millis":4,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n  warnings.warn(warning.format(ret))\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"num_epochs = 200\nfor epoch in range(num_epochs):\n    for inputs,labels in train_loader:\n        inputs = inputs.float()\n        labels = labels.float()\n        # Feed Forward\n        output = net(inputs)\n        # Loss Calculation\n        loss = criterion(output, labels)\n        # Clear the gradient buffer (we don't want to accumulate gradients)\n        optimizer.zero_grad()\n        # Backpropagation \n        loss.backward()\n        # Weight Update: w <-- w - lr * gradient\n        optimizer.step()\n        \n    #Accuracy\n    # Since we are using a sigmoid, we will need to perform some thresholding\n    output = (output>0.5).float()\n    # Accuracy: (output == labels).float().sum() / output.shape[0]\n    accuracy = (output == labels).float().mean()\n    # Print statistics \n    print(\"Epoch {}/{}, Loss: {:.3f}, Accuracy: {:.3f}\".format(epoch+1,num_epochs, loss, accuracy))","metadata":{"tags":[],"cell_id":"915b4c5a223b46319b6d340f1f35f785","source_hash":"dcb10dfc","execution_start":1672949615105,"execution_millis":5624,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Epoch 1/200, Loss: 0.544, Accuracy: 0.688\nEpoch 2/200, Loss: 0.432, Accuracy: 0.844\nEpoch 3/200, Loss: 0.435, Accuracy: 0.812\nEpoch 4/200, Loss: 0.560, Accuracy: 0.625\nEpoch 5/200, Loss: 0.408, Accuracy: 0.875\nEpoch 6/200, Loss: 0.526, Accuracy: 0.750\nEpoch 7/200, Loss: 0.407, Accuracy: 0.812\nEpoch 8/200, Loss: 0.584, Accuracy: 0.750\nEpoch 9/200, Loss: 0.379, Accuracy: 0.781\nEpoch 10/200, Loss: 0.455, Accuracy: 0.781\nEpoch 11/200, Loss: 0.531, Accuracy: 0.781\nEpoch 12/200, Loss: 0.429, Accuracy: 0.844\nEpoch 13/200, Loss: 0.515, Accuracy: 0.750\nEpoch 14/200, Loss: 0.504, Accuracy: 0.812\nEpoch 15/200, Loss: 0.426, Accuracy: 0.812\nEpoch 16/200, Loss: 0.498, Accuracy: 0.781\nEpoch 17/200, Loss: 0.479, Accuracy: 0.750\nEpoch 18/200, Loss: 0.444, Accuracy: 0.781\nEpoch 19/200, Loss: 0.464, Accuracy: 0.812\nEpoch 20/200, Loss: 0.329, Accuracy: 0.812\nEpoch 21/200, Loss: 0.586, Accuracy: 0.750\nEpoch 22/200, Loss: 0.422, Accuracy: 0.750\nEpoch 23/200, Loss: 0.392, Accuracy: 0.844\nEpoch 24/200, Loss: 0.454, Accuracy: 0.750\nEpoch 25/200, Loss: 0.607, Accuracy: 0.750\nEpoch 26/200, Loss: 0.422, Accuracy: 0.812\nEpoch 27/200, Loss: 0.276, Accuracy: 0.906\nEpoch 28/200, Loss: 0.454, Accuracy: 0.781\nEpoch 29/200, Loss: 0.444, Accuracy: 0.781\nEpoch 30/200, Loss: 0.350, Accuracy: 0.875\nEpoch 31/200, Loss: 0.474, Accuracy: 0.688\nEpoch 32/200, Loss: 0.416, Accuracy: 0.844\nEpoch 33/200, Loss: 0.491, Accuracy: 0.719\nEpoch 34/200, Loss: 0.512, Accuracy: 0.750\nEpoch 35/200, Loss: 0.481, Accuracy: 0.781\nEpoch 36/200, Loss: 0.398, Accuracy: 0.844\nEpoch 37/200, Loss: 0.421, Accuracy: 0.781\nEpoch 38/200, Loss: 0.550, Accuracy: 0.688\nEpoch 39/200, Loss: 0.346, Accuracy: 0.781\nEpoch 40/200, Loss: 0.423, Accuracy: 0.781\nEpoch 41/200, Loss: 0.456, Accuracy: 0.719\nEpoch 42/200, Loss: 0.571, Accuracy: 0.781\nEpoch 43/200, Loss: 0.510, Accuracy: 0.656\nEpoch 44/200, Loss: 0.339, Accuracy: 0.875\nEpoch 45/200, Loss: 0.350, Accuracy: 0.906\nEpoch 46/200, Loss: 0.502, Accuracy: 0.781\nEpoch 47/200, Loss: 0.390, Accuracy: 0.906\nEpoch 48/200, Loss: 0.457, Accuracy: 0.781\nEpoch 49/200, Loss: 0.378, Accuracy: 0.750\nEpoch 50/200, Loss: 0.342, Accuracy: 0.906\nEpoch 51/200, Loss: 0.615, Accuracy: 0.719\nEpoch 52/200, Loss: 0.350, Accuracy: 0.844\nEpoch 53/200, Loss: 0.457, Accuracy: 0.812\nEpoch 54/200, Loss: 0.466, Accuracy: 0.750\nEpoch 55/200, Loss: 0.306, Accuracy: 0.875\nEpoch 56/200, Loss: 0.466, Accuracy: 0.781\nEpoch 57/200, Loss: 0.260, Accuracy: 0.906\nEpoch 58/200, Loss: 0.550, Accuracy: 0.812\nEpoch 59/200, Loss: 0.274, Accuracy: 0.844\nEpoch 60/200, Loss: 0.447, Accuracy: 0.844\nEpoch 61/200, Loss: 0.429, Accuracy: 0.844\nEpoch 62/200, Loss: 0.390, Accuracy: 0.812\nEpoch 63/200, Loss: 0.525, Accuracy: 0.750\nEpoch 64/200, Loss: 0.579, Accuracy: 0.781\nEpoch 65/200, Loss: 0.364, Accuracy: 0.938\nEpoch 66/200, Loss: 0.581, Accuracy: 0.844\nEpoch 67/200, Loss: 0.326, Accuracy: 0.844\nEpoch 68/200, Loss: 0.568, Accuracy: 0.688\nEpoch 69/200, Loss: 0.397, Accuracy: 0.844\nEpoch 70/200, Loss: 0.576, Accuracy: 0.688\nEpoch 71/200, Loss: 0.518, Accuracy: 0.750\nEpoch 72/200, Loss: 0.380, Accuracy: 0.844\nEpoch 73/200, Loss: 0.590, Accuracy: 0.688\nEpoch 74/200, Loss: 0.445, Accuracy: 0.781\nEpoch 75/200, Loss: 0.517, Accuracy: 0.781\nEpoch 76/200, Loss: 0.478, Accuracy: 0.688\nEpoch 77/200, Loss: 0.512, Accuracy: 0.719\nEpoch 78/200, Loss: 0.525, Accuracy: 0.750\nEpoch 79/200, Loss: 0.493, Accuracy: 0.781\nEpoch 80/200, Loss: 0.449, Accuracy: 0.781\nEpoch 81/200, Loss: 0.419, Accuracy: 0.781\nEpoch 82/200, Loss: 0.426, Accuracy: 0.875\nEpoch 83/200, Loss: 0.416, Accuracy: 0.781\nEpoch 84/200, Loss: 0.415, Accuracy: 0.812\nEpoch 85/200, Loss: 0.510, Accuracy: 0.750\nEpoch 86/200, Loss: 0.352, Accuracy: 0.812\nEpoch 87/200, Loss: 0.366, Accuracy: 0.875\nEpoch 88/200, Loss: 0.383, Accuracy: 0.844\nEpoch 89/200, Loss: 0.473, Accuracy: 0.781\nEpoch 90/200, Loss: 0.505, Accuracy: 0.719\nEpoch 91/200, Loss: 0.468, Accuracy: 0.750\nEpoch 92/200, Loss: 0.598, Accuracy: 0.719\nEpoch 93/200, Loss: 0.383, Accuracy: 0.844\nEpoch 94/200, Loss: 0.295, Accuracy: 0.875\nEpoch 95/200, Loss: 0.447, Accuracy: 0.719\nEpoch 96/200, Loss: 0.373, Accuracy: 0.844\nEpoch 97/200, Loss: 0.497, Accuracy: 0.750\nEpoch 98/200, Loss: 0.424, Accuracy: 0.750\nEpoch 99/200, Loss: 0.330, Accuracy: 0.844\nEpoch 100/200, Loss: 0.434, Accuracy: 0.750\nEpoch 101/200, Loss: 0.461, Accuracy: 0.844\nEpoch 102/200, Loss: 0.554, Accuracy: 0.781\nEpoch 103/200, Loss: 0.490, Accuracy: 0.750\nEpoch 104/200, Loss: 0.468, Accuracy: 0.750\nEpoch 105/200, Loss: 0.489, Accuracy: 0.812\nEpoch 106/200, Loss: 0.358, Accuracy: 0.812\nEpoch 107/200, Loss: 0.308, Accuracy: 0.875\nEpoch 108/200, Loss: 0.424, Accuracy: 0.750\nEpoch 109/200, Loss: 0.404, Accuracy: 0.844\nEpoch 110/200, Loss: 0.356, Accuracy: 0.781\nEpoch 111/200, Loss: 0.524, Accuracy: 0.750\nEpoch 112/200, Loss: 0.454, Accuracy: 0.812\nEpoch 113/200, Loss: 0.299, Accuracy: 0.844\nEpoch 114/200, Loss: 0.450, Accuracy: 0.812\nEpoch 115/200, Loss: 0.553, Accuracy: 0.812\nEpoch 116/200, Loss: 0.492, Accuracy: 0.750\nEpoch 117/200, Loss: 0.465, Accuracy: 0.750\nEpoch 118/200, Loss: 0.358, Accuracy: 0.875\nEpoch 119/200, Loss: 0.466, Accuracy: 0.812\nEpoch 120/200, Loss: 0.456, Accuracy: 0.750\nEpoch 121/200, Loss: 0.564, Accuracy: 0.844\nEpoch 122/200, Loss: 0.475, Accuracy: 0.781\nEpoch 123/200, Loss: 0.331, Accuracy: 0.875\nEpoch 124/200, Loss: 0.421, Accuracy: 0.812\nEpoch 125/200, Loss: 0.558, Accuracy: 0.719\nEpoch 126/200, Loss: 0.274, Accuracy: 0.875\nEpoch 127/200, Loss: 0.527, Accuracy: 0.750\nEpoch 128/200, Loss: 0.445, Accuracy: 0.781\nEpoch 129/200, Loss: 0.443, Accuracy: 0.750\nEpoch 130/200, Loss: 0.345, Accuracy: 0.875\nEpoch 131/200, Loss: 0.360, Accuracy: 0.812\nEpoch 132/200, Loss: 0.312, Accuracy: 0.875\nEpoch 133/200, Loss: 0.480, Accuracy: 0.781\nEpoch 134/200, Loss: 0.287, Accuracy: 0.875\nEpoch 135/200, Loss: 0.418, Accuracy: 0.750\nEpoch 136/200, Loss: 0.302, Accuracy: 0.844\nEpoch 137/200, Loss: 0.352, Accuracy: 0.812\nEpoch 138/200, Loss: 0.341, Accuracy: 0.938\nEpoch 139/200, Loss: 0.230, Accuracy: 0.875\nEpoch 140/200, Loss: 0.386, Accuracy: 0.844\nEpoch 141/200, Loss: 0.434, Accuracy: 0.781\nEpoch 142/200, Loss: 0.333, Accuracy: 0.844\nEpoch 143/200, Loss: 0.426, Accuracy: 0.781\nEpoch 144/200, Loss: 0.395, Accuracy: 0.781\nEpoch 145/200, Loss: 0.473, Accuracy: 0.812\nEpoch 146/200, Loss: 0.489, Accuracy: 0.844\nEpoch 147/200, Loss: 0.311, Accuracy: 0.906\nEpoch 148/200, Loss: 0.427, Accuracy: 0.781\nEpoch 149/200, Loss: 0.310, Accuracy: 0.844\nEpoch 150/200, Loss: 0.599, Accuracy: 0.719\nEpoch 151/200, Loss: 0.309, Accuracy: 0.875\nEpoch 152/200, Loss: 0.316, Accuracy: 0.875\nEpoch 153/200, Loss: 0.387, Accuracy: 0.781\nEpoch 154/200, Loss: 0.517, Accuracy: 0.875\nEpoch 155/200, Loss: 0.345, Accuracy: 0.812\nEpoch 156/200, Loss: 0.377, Accuracy: 0.812\nEpoch 157/200, Loss: 0.429, Accuracy: 0.781\nEpoch 158/200, Loss: 0.414, Accuracy: 0.844\nEpoch 159/200, Loss: 0.616, Accuracy: 0.750\nEpoch 160/200, Loss: 0.232, Accuracy: 0.969\nEpoch 161/200, Loss: 0.342, Accuracy: 0.844\nEpoch 162/200, Loss: 0.344, Accuracy: 0.844\nEpoch 163/200, Loss: 0.386, Accuracy: 0.812\nEpoch 164/200, Loss: 0.428, Accuracy: 0.844\nEpoch 165/200, Loss: 0.523, Accuracy: 0.750\nEpoch 166/200, Loss: 0.494, Accuracy: 0.750\nEpoch 167/200, Loss: 0.310, Accuracy: 0.906\nEpoch 168/200, Loss: 0.314, Accuracy: 0.938\nEpoch 169/200, Loss: 0.367, Accuracy: 0.844\nEpoch 170/200, Loss: 0.208, Accuracy: 0.938\nEpoch 171/200, Loss: 0.276, Accuracy: 0.906\nEpoch 172/200, Loss: 0.357, Accuracy: 0.875\nEpoch 173/200, Loss: 0.491, Accuracy: 0.750\nEpoch 174/200, Loss: 0.584, Accuracy: 0.688\nEpoch 175/200, Loss: 0.583, Accuracy: 0.750\nEpoch 176/200, Loss: 0.612, Accuracy: 0.750\nEpoch 177/200, Loss: 0.459, Accuracy: 0.812\nEpoch 178/200, Loss: 0.351, Accuracy: 0.812\nEpoch 179/200, Loss: 0.523, Accuracy: 0.750\nEpoch 180/200, Loss: 0.447, Accuracy: 0.812\nEpoch 181/200, Loss: 0.332, Accuracy: 0.875\nEpoch 182/200, Loss: 0.312, Accuracy: 0.844\nEpoch 183/200, Loss: 0.348, Accuracy: 0.812\nEpoch 184/200, Loss: 0.325, Accuracy: 0.844\nEpoch 185/200, Loss: 0.312, Accuracy: 0.844\nEpoch 186/200, Loss: 0.372, Accuracy: 0.844\nEpoch 187/200, Loss: 0.412, Accuracy: 0.781\nEpoch 188/200, Loss: 0.371, Accuracy: 0.781\nEpoch 189/200, Loss: 0.646, Accuracy: 0.781\nEpoch 190/200, Loss: 0.391, Accuracy: 0.812\nEpoch 191/200, Loss: 0.431, Accuracy: 0.750\nEpoch 192/200, Loss: 0.300, Accuracy: 0.875\nEpoch 193/200, Loss: 0.354, Accuracy: 0.844\nEpoch 194/200, Loss: 0.384, Accuracy: 0.875\nEpoch 195/200, Loss: 0.173, Accuracy: 0.969\nEpoch 196/200, Loss: 0.429, Accuracy: 0.812\nEpoch 197/200, Loss: 0.354, Accuracy: 0.844\nEpoch 198/200, Loss: 0.440, Accuracy: 0.750\nEpoch 199/200, Loss: 0.581, Accuracy: 0.750\nEpoch 200/200, Loss: 0.327, Accuracy: 0.844\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=49da15f7-246c-45df-bc8f-6f9233c2b1e1' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"62de1314d4b24ed5858137eaa2ce1398","deepnote_persisted_session":{"createdAt":"2023-01-05T20:31:36.066Z"},"deepnote_execution_queue":[]}}